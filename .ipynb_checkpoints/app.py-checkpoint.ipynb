{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Set page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"CORD-19 Research Analysis\",\n",
    "    page_icon=\"ðŸ“š\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Load data\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    try:\n",
    "        df = pd.read_csv('data/metadata.csv')\n",
    "        # Data cleaning\n",
    "        df_cleaned = df.copy()\n",
    "        df_cleaned['abstract'] = df_cleaned['abstract'].fillna('')\n",
    "        df_cleaned['publish_time'] = pd.to_datetime(df_cleaned['publish_time'], errors='coerce')\n",
    "        df_cleaned['year'] = df_cleaned['publish_time'].dt.year\n",
    "        df_cleaned['abstract_word_count'] = df_cleaned['abstract'].apply(lambda x: len(str(x).split()))\n",
    "        return df_cleaned\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Please download the metadata.csv file from Kaggle and place it in the data/ folder\")\n",
    "        st.stop()\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# Sidebar\n",
    "st.sidebar.title(\"CORD-19 Analysis Dashboard\")\n",
    "st.sidebar.markdown(\"Explore COVID-19 research papers metadata\")\n",
    "\n",
    "# Filters\n",
    "st.sidebar.header(\"Filters\")\n",
    "year_range = st.sidebar.slider(\n",
    "    \"Select Year Range\",\n",
    "    min_value=int(df['year'].min()),\n",
    "    max_value=int(df['year'].max()),\n",
    "    value=(2020, 2021)\n",
    ")\n",
    "\n",
    "min_word_count = st.sidebar.slider(\n",
    "    \"Minimum Abstract Word Count\",\n",
    "    min_value=0,\n",
    "    max_value=500,\n",
    "    value=50\n",
    ")\n",
    "\n",
    "source_filter = st.sidebar.multiselect(\n",
    "    \"Select Sources\",\n",
    "    options=df['source_x'].dropna().unique(),\n",
    "    default=df['source_x'].dropna().unique()[:3]\n",
    ")\n",
    "\n",
    "# Apply filters\n",
    "filtered_df = df[\n",
    "    (df['year'] >= year_range[0]) & \n",
    "    (df['year'] <= year_range[1]) &\n",
    "    (df['abstract_word_count'] >= min_word_count)\n",
    "]\n",
    "\n",
    "if source_filter:\n",
    "    filtered_df = filtered_df[filtered_df['source_x'].isin(source_filter)]\n",
    "\n",
    "# Main content\n",
    "st.title(\"ðŸ“Š CORD-19 Research Dataset Analysis\")\n",
    "st.markdown(\"\"\"\n",
    "This dashboard provides insights into the COVID-19 Open Research Dataset (CORD-19) metadata.\n",
    "Explore publications over time, top journals, and word frequency in titles.\n",
    "\"\"\")\n",
    "\n",
    "# Key metrics\n",
    "col1, col2, col3, col4 = st.columns(4)\n",
    "with col1:\n",
    "    st.metric(\"Total Papers\", len(filtered_df))\n",
    "with col2:\n",
    "    st.metric(\"Unique Journals\", filtered_df['journal'].nunique())\n",
    "with col3:\n",
    "    st.metric(\"Average Abstract Length\", f\"{filtered_df['abstract_word_count'].mean():.1f} words\")\n",
    "with col4:\n",
    "    st.metric(\"Time Range\", f\"{year_range[0]} - {year_range[1]}\")\n",
    "\n",
    "# Tabs\n",
    "tab1, tab2, tab3, tab4 = st.tabs([\"Overview\", \"Publications\", \"Word Analysis\", \"Data Sample\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"Dataset Overview\")\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Publications by Year\")\n",
    "        yearly_counts = filtered_df['year'].value_counts().sort_index()\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        yearly_counts.plot(kind='bar', ax=ax, color='skyblue')\n",
    "        ax.set_title('Publications by Year')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Number of Publications')\n",
    "        plt.xticks(rotation=45)\n",
    "        st.pyplot(fig)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Top Journals\")\n",
    "        top_journals = filtered_df['journal'].value_counts().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        top_journals.plot(kind='bar', ax=ax, color='lightgreen')\n",
    "        ax.set_title('Top 10 Journals')\n",
    "        ax.set_xlabel('Journal')\n",
    "        ax.set_ylabel('Number of Publications')\n",
    "        plt.xticks(rotation=45)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "with tab2:\n",
    "    st.header(\"Publication Analysis\")\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(\"Source Distribution\")\n",
    "        source_counts = filtered_df['source_x'].value_counts().head(10)\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.pie(source_counts.values, labels=source_counts.index, autopct='%1.1f%%')\n",
    "        ax.set_title('Top 10 Sources')\n",
    "        st.pyplot(fig)\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(\"Abstract Length Distribution\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.hist(filtered_df['abstract_word_count'], bins=50, color='orange', alpha=0.7)\n",
    "        ax.set_title('Distribution of Abstract Word Count')\n",
    "        ax.set_xlabel('Word Count')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        st.pyplot(fig)\n",
    "\n",
    "with tab3:\n",
    "    st.header(\"Word Analysis\")\n",
    "    \n",
    "    # Word cloud\n",
    "    st.subheader(\"Word Cloud of Paper Titles\")\n",
    "    all_titles = ' '.join(filtered_df['title'].dropna().astype(str))\n",
    "    if all_titles.strip():\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_titles)\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('Word Cloud of Paper Titles')\n",
    "        st.pyplot(fig)\n",
    "    else:\n",
    "        st.warning(\"No titles available for the selected filters\")\n",
    "\n",
    "with tab4:\n",
    "    st.header(\"Data Sample\")\n",
    "    st.subheader(\"Filtered Dataset Preview\")\n",
    "    \n",
    "    # Show sample data\n",
    "    st.dataframe(\n",
    "        filtered_df[['title', 'journal', 'publish_time', 'source_x', 'abstract_word_count']].head(20),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    # Download button\n",
    "    csv = filtered_df.to_csv(index=False)\n",
    "    st.download_button(\n",
    "        label=\"Download filtered data as CSV\",\n",
    "        data=csv,\n",
    "        file_name=\"filtered_cord19_data.csv\",\n",
    "        mime=\"text/csv\"\n",
    "    )\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "**Data Source**: [CORD-19 Research Dataset on Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
